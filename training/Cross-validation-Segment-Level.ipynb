{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "included-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime as dt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.robust import RobustWeightedKMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn import svm\n",
    "import networkx as nx\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667154ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm directories are in place\n",
    "TARGET_AREA = 'davidson'\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../data', TARGET_AREA)):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data', TARGET_AREA)\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'ratings')):\n",
    "    os.mkdir(os.path.join(data_dir, 'ratings'))\n",
    "ratings_dir = os.path.join(data_dir, 'ratings')\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../img')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "img_dir = os.path.join(os.getcwd(), '../img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_trust_score = []\n",
    "for loop run eeta: \n",
    "    for loop run T:\n",
    "        returned_trust_score.apped( cal_trust_score())\n",
    "# for the cross validation create a search space for K and eeta \n",
    "# where K is \n",
    "def cal_trust_score(file_path,k,eeta): \n",
    "    rating_A = pd.read_csv(file_path)\n",
    "#     print(rating_A)\n",
    "    l_original = rating_A.drop(rating_A.columns[0], axis=1)\n",
    "#     print(l_original)\n",
    "    N  = len(l_original)\n",
    "    Window = len(l_original.columns)\n",
    "    temp = np.zeros(shape=(N,Window))\n",
    "    x = pd.DataFrame(temp)\n",
    "    cw = x.copy()\n",
    "    w = x.copy()\n",
    "    \n",
    "    K = 4# maximum rating level #these are parameters\n",
    "    eeta = eeta; # these are paramters\n",
    "    M_BR = 4 \n",
    "    \n",
    "    l1_original = l_original.apply(np.sort, axis = 1)\n",
    "#     print(l1_original)\n",
    "    for i in range(N):\n",
    "        for j in range(Window):\n",
    "            x.iloc[i,j] = 1 + ((K-1)*j)/Window\n",
    "#     print(x)\n",
    "    temp1 = np.zeros(shape=N)\n",
    "    std_dr = pd.DataFrame(temp1)\n",
    "    for i in range(N):\n",
    "        std_dr.iloc[i] = np.std(l1_original[i])    \n",
    "    for i in range(len(std_dr)):\n",
    "        if int(std_dr.iloc[i]) == 0:\n",
    "            std_dr.iloc[i] = np.mean(std_dr) \n",
    "#     print(std_dr)\n",
    "    for i in range(N):\n",
    "        for j in range(Window):         \n",
    "            cw.iloc[i,j] = (1/(math.sqrt(2*3.1415)*std_dr.iloc[i,0]))*(math.exp((-1*math.pow((x.iloc[i,j]-M_BR),2))/(2*math.pow(std_dr.iloc[i,0],2))))\n",
    "#     print(cw)  \n",
    "    for i in range(N):\n",
    "        for j in range(Window):\n",
    "            w.iloc[i,j] = cw.iloc[i,j]/np.sum(cw.iloc[i,:])\n",
    "#     print(w)  \n",
    "    R = np.zeros(shape=N)\n",
    "    for segment in range(N):\n",
    "        temp2 = np.zeros(shape=(4,Window))\n",
    "        I = pd.DataFrame(temp2)\n",
    "        #creates the evasion discrete levels.\n",
    "        for j in range(Window):\n",
    "            if l_original.iloc[segment,j] == 1:\n",
    "                I.iloc[0,j] = 1\n",
    "            elif l_original.iloc[segment,j] == 2:\n",
    "                I.iloc[1,j] = 1\n",
    "            elif l_original.iloc[segment,j] == 3:\n",
    "                I.iloc[2,j] = 1\n",
    "            else:\n",
    "                I.iloc[3,j] = 1\n",
    "        temp3 = np.zeros(shape=4)\n",
    "        wd = pd.DataFrame(temp3)\n",
    "        for i in range(4):\n",
    "            for j in range(Window):\n",
    "                wd.iloc[i,0] = wd.iloc[i,0] + I.iloc[i,j]*w.iloc[segment,j]\n",
    "\n",
    "        for i in range(4):\n",
    "            R[segment] = R[segment] + (i+1)*wd.iloc[i,0]\n",
    "#     print(R)\n",
    "    TR = np.zeros(shape=N)\n",
    "    for i in range(N):\n",
    "        TR[i] = (1/math.pow(K,eeta))*(math.pow(R[i],eeta))\n",
    "#     print(TR)\n",
    "    return TR,rating_A.iloc[:, 0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respective-swiss",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m list_of_ratings_per_cluster_per_incident_dir  \u001b[38;5;241m=\u001b[39m  os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mratings_dir\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLARGEWINDOW_100\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m files_25_ratings \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(list_of_ratings_per_cluster_per_incident_dir)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files_25_ratings))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings_dir' is not defined"
     ]
    }
   ],
   "source": [
    "list_of_ratings_per_cluster_per_incident_dir  =  os.path.join(ratings_dir, 'LARGEWINDOW_100')\n",
    "files_25_ratings = os.listdir(list_of_ratings_per_cluster_per_incident_dir)\n",
    "print(len(files_25_ratings))\n",
    "\n",
    "trust_score=[]\n",
    "prediction =[] #0 means high trusted 1 means less trusted \n",
    "segment_list_per_cluster = []\n",
    "dead_idx = []\n",
    "for i, file_path in enumerate(files_25_ratings):\n",
    "    fp = os.path.join(list_of_ratings_per_cluster_per_incident_dir, file_path)\n",
    "    TR,list_segments = cal_trust_score(fp)\n",
    "    trust_score.append(TR)\n",
    "    segment_list_per_cluster.append(list_segments)\n",
    "    print(TR)\n",
    "    # kmeans = KMeans(n_clusters=2)\n",
    "    kmeans = KMedoids(n_clusters=2, init='heuristic', method='pam', max_iter=1000)\n",
    "    # kmeans = svm.OneClassSVM(kernel='rbf', gamma=0.00005) \n",
    "    # Change to k-medoids, k-means++, robust k-means, svm\n",
    "    kmeans.fit(TR.reshape(-1,1))    \n",
    "    y_kmeans = kmeans.predict(TR.reshape(-1,1))\n",
    "    prediction.append(y_kmeans)\n",
    "    print(y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bf13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighboring_segments(L_XDSegID, cluster_list, segment, level=5, undirected=False):\n",
    "    neighbor_df = {'XDSegID': [], 'level': []}\n",
    "    done = []\n",
    "    for l in range(level + 1):\n",
    "        H = nx.ego_graph(L_XDSegID, n=segment, radius=l, undirected=undirected)\n",
    "        for n in H.nodes:\n",
    "            if n not in done:\n",
    "                if n in cluster_list:\n",
    "#                     print(n, l)\n",
    "                    neighbor_df['XDSegID'].append(n)\n",
    "                    neighbor_df['level'].append(l)\n",
    "                    done.append(n)\n",
    "    return pd.DataFrame(neighbor_df).sort_values(by='level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f16d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 6906 nodes and 15264 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2725/3976196170.py:6: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  print(nx.info(L_XDSegID))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(data_dir, 'segment_network_graphs')):\n",
    "    os.mkdir(os.path.join(data_dir, 'segment_network_graphs'))\n",
    "graphs_dir = os.path.join(data_dir, 'segment_network_graphs')\n",
    "fp = os.path.join(graphs_dir, 'line_segment_graph.gml')\n",
    "L_XDSegID = nx.read_gml(fp, destringizer=int)\n",
    "print(nx.info(L_XDSegID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0573a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/seconddrive/Anomaly_Detection_2021/extension/../data/davidson/generated_clusters/optimized_clustering_0.7_0.85_maxr085_restricted.pkl\n"
     ]
    }
   ],
   "source": [
    "fp_cluster = os.path.join(data_dir, \"generated_clusters/optimized_clustering_0.7_0.85_maxr085_restricted.pkl\")\n",
    "print(fp_cluster)\n",
    "with open(fp_cluster, 'rb') as handle:\n",
    "    cluster_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee79269",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(data_dir, 'all_incidents_ground_truth.pkl')\n",
    "all_incidents_gt = pd.read_pickle(fp)\n",
    "all_incidents_gt = all_incidents_gt[all_incidents_gt['cluster_head'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "245806ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_data_path  =  os.path.join(data_dir, \"generated_clusters/maxr085_incident_ratios/incidents_GT\")\n",
    "files_GT = os.listdir(ground_truth_data_path)\n",
    "incident_GT = []\n",
    "i = 0\n",
    "while i< len(files_GT):\n",
    "    fp = os.path.join(ground_truth_data_path, files_GT[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        incident_GT.append( pickle.load(handle))\n",
    "    i+=1\n",
    "incident_GT_Frame = pd.concat(incident_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c716762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = 4\n",
    "neighbour_segments_per_incident_per_cluster = []\n",
    "list_of_cluster = []\n",
    "found = 0\n",
    "for i in range(0,len(files_25_ratings)):\n",
    "    cluster_head = files_25_ratings[i].split(\"_\")[1]\n",
    "    start = dt.datetime.strptime(files_25_ratings[i].split(\"_\")[2], '%Y%m%d%H%M%S')\n",
    "    month = start.month\n",
    "    day = start.day\n",
    "    list_of_cluster.append(cluster_head)\n",
    "    \n",
    "    incident_segment_frame = incident_GT_Frame[(incident_GT_Frame['cluster_head'] == int(cluster_head)) &\\\n",
    "                             ((incident_GT_Frame.index.month == int(month))&( incident_GT_Frame.index.day==int(day)))]\n",
    "    if(len(incident_segment_frame) == 0): \n",
    "        continue\n",
    "    found+=1\n",
    "    segment_to_check = incident_segment_frame['XDSegID'].tolist()[0]\n",
    "    neighbour_segments = get_neighboring_segments(L_XDSegID, cluster_list[int(cluster_head)], segment_to_check, level, undirected=True)\n",
    "    neighbour_segments_per_incident_per_cluster.append(neighbour_segments)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1884cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "0.01 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_rate_sum = 0\n",
    "success_count = 0\n",
    "\n",
    "false_positives = 0\n",
    "detection_counts = 0\n",
    "\n",
    "# for fI in tqdm(range(0,len(files_25_ratings))):\n",
    "for fI in tqdm(range(2, 3)):\n",
    "    TR_prediction = prediction[fI]\n",
    "    neighbour_segments_frame =  neighbour_segments_per_incident_per_cluster[fI]\n",
    "    neighbour_segments_list = neighbour_segments_frame['XDSegID'].tolist()\n",
    "    segment_list = segment_list_per_cluster[fI]\n",
    "    for i in range(0,len(TR_prediction)):\n",
    "        if(TR_prediction[i] == 1 ):\n",
    "            if(segment_list[i]  in neighbour_segments_list ):\n",
    "                label = neighbour_segments_frame[neighbour_segments_frame['XDSegID']==segment_list[i]]['level'].tolist()[0]\n",
    "                if((label == int(1))or(label == int(0))) :\n",
    "                    success_count = success_count + 1\n",
    "                    break\n",
    "    break\n",
    "print(success_count, success_rate_sum)\n",
    "\n",
    "active_ratings = len(files_25_ratings)\n",
    "avg_success_rate = success_count/(active_ratings)\n",
    "print(avg_success_rate, active_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11620605",
   "metadata": {},
   "source": [
    "# Identifying other metrics\n",
    "* See lines `10-13`, I set it up as follows:\n",
    "    * If segment is in `0` or `1` segment level AND prediction is equal to `1` => TP\n",
    "    * If segment is in `0` or `1` segment level AND prediction is equal to `0` => FN\n",
    "    * If segment is NOT in `0` or `1` segment level AND prediction is equal to `1` => FP\n",
    "    * If segment is NOT in `0` or `1` segment level AND prediction is equal to `0` => TN\n",
    "* Not sure if this the correct way to do it, our previous code only measures TP as:\n",
    "    * If ANY segment is in 0 or 1 segment level AND prediction is equal to 1 count as 1 success and move on to next incident\n",
    "    * `results_arr.sum()['OLD_TP'] / total_incident_ratings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f30b09d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 374.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "results_arr = []\n",
    "for fI in tqdm(range(len(files_25_ratings))):\n",
    "    TR_prediction = prediction[fI]\n",
    "    segment_list = segment_list_per_cluster[fI]\n",
    "    pred_df = pd.DataFrame(np.column_stack((segment_list, TR_prediction)), columns=['XDSegID', 'pred'])\n",
    "    neighbour_segments_frame =  neighbour_segments_per_incident_per_cluster[fI]\n",
    "    pred_df = pd.merge(pred_df, neighbour_segments_frame, left_on='XDSegID', right_on='XDSegID', how='outer')\n",
    "    pred_df = pred_df.fillna(neighbour_segments_frame.level.max() + 1).sort_values('level')\n",
    "    \n",
    "    TP = pred_df[(pred_df['level'].isin([0, 1])) & (pred_df['pred'] == 1)]\n",
    "    FN = pred_df[(pred_df['level'].isin([0, 1])) & (pred_df['pred'] == 0)]\n",
    "    FP = pred_df[(~pred_df['level'].isin([0, 1])) & (pred_df['pred'] == 1)]\n",
    "    TN = pred_df[(~pred_df['level'].isin([0, 1])) & (pred_df['pred'] == 0)]\n",
    "    \n",
    "    OLD_TP = 0\n",
    "    if len(TP) > 0:\n",
    "        OLD_TP = 1\n",
    "\n",
    "    # display(pred_df)\n",
    "    results_arr.append([OLD_TP, len(TP), len(FP), len(TN), len(FN)])\n",
    "    # break\n",
    "results_arr = pd.DataFrame(results_arr, columns=['OLD_TP', 'TP','FP','TN','FN'])\n",
    "\n",
    "# OLD_TP\n",
    "results_arr.sum()['OLD_TP']/len(files_25_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "842705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed metrics\n",
    "results_arr['precision'] = results_arr['TP'] / (results_arr['TP'] + results_arr['FP'])\n",
    "results_arr['TPR'] = results_arr['TP'] / (results_arr['TP'] + results_arr['FN'])\n",
    "results_arr['FPR'] = results_arr['FP'] / (results_arr['FP'] + results_arr['TN'])\n",
    "results_arr['BAL_ACC'] = (results_arr['TPR'] + (1 - results_arr['FPR'])) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8a79d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4691689008042895, 0.520618556701031, 0.4742751720516293)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPR = results_arr['FP'].sum() / (results_arr['FP'].sum() + results_arr['TN'].sum())\n",
    "TPR = results_arr['TP'].sum() / (results_arr['TP'].sum() + results_arr['FN'].sum())\n",
    "BAL_ACC = (TPR + (1 - FPR)) / 2\n",
    "TPR, FPR, BAL_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1966674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_arr[['BAL_ACC']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Davidson: 0.79, 100 files\n",
    "# Hamilton: 0.6464, 99 files\n",
    "# Shelby:  0.6782, 87 files\n",
    "# Knox: 0.68,100 files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92393db1",
   "metadata": {},
   "source": [
    "# IGNORE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd686b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7ff6e2",
   "metadata": {},
   "source": [
    "## Putting it all together for all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dfdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = ['davidson', 'hamilton', 'knox', 'shelby']\n",
    "cities = ['Nashville', 'Chattanooga', 'Knoxville', 'Memphis']\n",
    "level = 4\n",
    "\n",
    "def evaluate_ratings_for_county(TARGET_AREA):\n",
    "    county_idx = counties.index(TARGET_AREA)\n",
    "    city = cities[county_idx]\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), '../data', TARGET_AREA)):\n",
    "        raise OSError(\"Must first download data, see README.md\")\n",
    "    data_dir = os.path.join(os.getcwd(), '../data', TARGET_AREA)\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_dir, 'ratings')):\n",
    "        os.mkdir(os.path.join(data_dir, 'ratings'))\n",
    "    ratings_dir = os.path.join(data_dir, 'ratings')\n",
    "        \n",
    "    if not os.path.exists(os.path.join(data_dir, 'segment_network_graphs')):\n",
    "        os.mkdir(os.path.join(data_dir, 'segment_network_graphs'))\n",
    "    graphs_dir = os.path.join(data_dir, 'segment_network_graphs')\n",
    "\n",
    "    list_of_ratings_per_cluster_per_incident_dir  =  os.path.join(ratings_dir, 'LARGEWINDOW_100')\n",
    "    files_25_ratings = os.listdir(list_of_ratings_per_cluster_per_incident_dir)\n",
    "\n",
    "    trust_score=[]\n",
    "    prediction =[] #0 means high trusted 1 means less trusted \n",
    "    segment_list_per_cluster = []\n",
    "    for file_path in files_25_ratings:\n",
    "        fp = os.path.join(list_of_ratings_per_cluster_per_incident_dir, file_path)\n",
    "        TR,list_segments = cal_trust_score(fp)\n",
    "        trust_score.append(TR)\n",
    "        segment_list_per_cluster.append(list_segments)\n",
    "        # kmeans = KMeans(n_clusters=2)\n",
    "        # kmeans = RobustWeightedKMeans(n_clusters=2, weighting='mom', max_iter=300)\n",
    "        # kmeans = KMedoids(n_clusters=2, init='heuristic', method='pam', max_iter=1000)\n",
    "        # kmeans = KMedoids(n_clusters=2, init='k-medoids++', method='pam', max_iter=500)\n",
    "        \n",
    "        kmeans = svm.OneClassSVM(kernel='rbf', gamma=0.00005) \n",
    "        kmeans.fit(TR.reshape(-1,1))\n",
    "        y_kmeans = kmeans.predict(TR.reshape(-1,1))\n",
    "        prediction.append(y_kmeans)\n",
    "        \n",
    "    fp = os.path.join(graphs_dir, 'line_segment_graph.gml')\n",
    "    L_XDSegID = nx.read_gml(fp, destringizer=int)\n",
    "\n",
    "    ground_truth_data_path  =  os.path.join(data_dir, \"generated_clusters/maxr085_incident_ratios/incidents_GT\")\n",
    "    files_GT = os.listdir(ground_truth_data_path)\n",
    "    incident_GT = []\n",
    "    i = 0\n",
    "    while i < len(files_GT):\n",
    "        fp = os.path.join(ground_truth_data_path, files_GT[i])\n",
    "        with open(fp, 'rb') as handle:\n",
    "            incident_GT.append( pickle.load(handle))\n",
    "        i+=1\n",
    "    incident_GT_Frame = pd.concat(incident_GT)\n",
    "\n",
    "    fp_cluster = os.path.join(data_dir, \"generated_clusters/optimized_clustering_0.7_0.85_maxr085_restricted.pkl\")\n",
    "\n",
    "    with open(fp_cluster, 'rb') as handle:\n",
    "        cluster_list = pickle.load(handle)\n",
    "\n",
    "    neighbour_segments_per_incident_per_cluster = []\n",
    "    list_of_cluster = []\n",
    "    for i in range(0, len(files_25_ratings)):\n",
    "        cluster_head = files_25_ratings[i].split(\"_\")[1]\n",
    "        start = dt.datetime.strptime(files_25_ratings[i].split(\"_\")[2], '%Y%m%d%H%M%S')\n",
    "        month = start.month\n",
    "        day = start.day\n",
    "        list_of_cluster.append(cluster_head)\n",
    "        \n",
    "        incident_segment_frame = incident_GT_Frame[(incident_GT_Frame['cluster_head'] == int(cluster_head)) &\\\n",
    "                                ((incident_GT_Frame.index.month == int(month))&( incident_GT_Frame.index.day==int(day)))]\n",
    "        if(len(incident_segment_frame) == 0): \n",
    "            continue\n",
    "        segment_to_check = incident_segment_frame['XDSegID'].tolist()[0]\n",
    "        neighbour_segments = get_neighboring_segments(L_XDSegID, cluster_list[int(cluster_head)], segment_to_check, level, undirected=True)\n",
    "        neighbour_segments_per_incident_per_cluster.append(neighbour_segments)\n",
    "        \n",
    "    success_rate_sum = 0\n",
    "    success_count = 0\n",
    "    for fI in range(0,len(files_25_ratings)):\n",
    "        TR_prediction = prediction[fI]\n",
    "        neighbour_segments_frame =  neighbour_segments_per_incident_per_cluster[fI]\n",
    "        neighbour_segments_list = neighbour_segments_frame['XDSegID'].tolist()\n",
    "        segment_list = segment_list_per_cluster[fI]\n",
    "        for i in range(0,len(TR_prediction)):\n",
    "            if(TR_prediction[i] == 1 ):\n",
    "                if(segment_list[i]  in neighbour_segments_list ):\n",
    "                    label = neighbour_segments_frame[neighbour_segments_frame['XDSegID']==segment_list[i]]['level'].tolist()[0]\n",
    "                    if((label == int(1))or(label == int(0))) :\n",
    "                        success_count = success_count + 1\n",
    "                        break\n",
    "\n",
    "    avg_success_rate = success_count/(len(files_25_ratings))\n",
    "    print(f\"{city},{avg_success_rate:.4f}\")\n",
    "    return city, avg_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_arr = []\n",
    "runs = 5\n",
    "for run in range(runs):\n",
    "    city_arr = []\n",
    "    avg_success_rate_arr = []\n",
    "    for county in counties:\n",
    "        city, avg_success_rate = evaluate_ratings_for_county(county)\n",
    "        city_arr.append(city)\n",
    "        avg_success_rate_arr.append(avg_success_rate)\n",
    "    results = np.column_stack(([run]*len(city_arr), city_arr, avg_success_rate_arr))\n",
    "    results = pd.DataFrame(results, columns=['run', 'city', 'score'])\n",
    "    res_df_arr.append(results)\n",
    "results_df = pd.concat(res_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = os.path.join(data_dir, 'svm_evaluation_ratings_for_county.pkl')\n",
    "# results_df.to_pickle(fp)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = os.path.join(data_dir, 'evaluation_ratings_for_county.pkl')\n",
    "# results_df = pd.read_pickle(fp)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.pivot_table(results_df, values = 'score', index=['run'], columns = 'city').boxplot()\n",
    "ax.set_ylim(0.0, 1.1)\n",
    "ax.set_xlabel('City')\n",
    "ax.set_ylabel('Segment Level Detection Accuracy')\n",
    "fp = os.path.join('../img', 'svm_segment_level_detection_accuracy.png')\n",
    "plt.savefig(fp, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99bebb",
   "metadata": {},
   "source": [
    "# Visualizing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), '../data')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting different clustering models\n",
    "model_evals = ['kmeans_evaluation_ratings_for_county.pkl',\n",
    "               'kmeanspp_evaluation_ratings_for_county.pkl',\n",
    "               'kmedoids_evaluation_ratings_for_county.pkl',\n",
    "               'robust_evaluation_ratings_for_county.pkl',\n",
    "               'svm_evaluation_ratings_for_county.pkl']\n",
    "\n",
    "markers = ['o', 's', '^', 'x', '*']\n",
    "fig, ax = plt.subplots()\n",
    "results_arr = []\n",
    "for i, model_eval in enumerate(model_evals):\n",
    "    fp = os.path.join(data_dir, model_eval)\n",
    "    df = pd.read_pickle(fp)\n",
    "    df = pd.pivot_table(df, values='score', columns='city', index='run')\n",
    "    print(df.max().tolist())\n",
    "    results_arr.append(df.max().tolist())\n",
    "    # ax.plot(df.max(), marker=markers[i], label=model_eval.split(\"_\")[0])\n",
    "# ax.legend()\n",
    "df = pd.DataFrame(results_arr, columns=df.columns)\n",
    "df.boxplot(ax=ax)\n",
    "ax.set_ylim(0.0, 1.1)\n",
    "\n",
    "fp = os.path.join(data_dir, 'kmedoids_evaluation_ratings_for_county.pkl')\n",
    "df = pd.read_pickle(fp)\n",
    "df = pd.pivot_table(df, values='score', columns='city', index='run')\n",
    "# ax.plot(df.iloc[0].tolist(), marker='o')\n",
    "# df.plot(ax=ax)\n",
    "\n",
    "ax.set_ylim(0.0, 1.1)\n",
    "ax.set_xlabel('Cities')\n",
    "ax.set_ylabel('Segment Level Detection Accuracy')\n",
    "fp = os.path.join('../img', 'segment_level_detection_accuracy.png')\n",
    "plt.savefig(fp, dpi=200, bbox_inches='tight', facecolor='white', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29654b81",
   "metadata": {},
   "source": [
    "# Below not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42868568",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fI in range(0,len(files_25_ratings)):\n",
    "    print('*************',list_of_cluster[fI],'***************')\n",
    "    TC = trust_score[fI]\n",
    "    TR_prediction = prediction[fI]\n",
    "    segment_list = segment_list_per_cluster[fI]\n",
    "    for i in range(0,len(TR_prediction)):\n",
    "        if(TR_prediction[i] == 1 ):\n",
    "            if(segment_list[i]  in neighbour_segments_list ):\n",
    "                label = neighbour_segments_frame[neighbour_segments_frame['XDSegID']==segment_list[i]]['level'].tolist()[0]\n",
    "                print(\"segment: \",segment_list[i],\" Trust Score: \",TC[i],' Level: ',label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac0ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "success_rate_sum = 0\n",
    "for fI in range(0,len(files_25_ratings)):\n",
    "    TC = trust_score[fI]\n",
    "    TR_prediction = prediction[fI]\n",
    "    print('*************',list_of_cluster[fI],'***************')\n",
    "\n",
    "#     print(TR_prediction)\n",
    "    neighbour_segments_frame =  neighbour_segments_per_incident_per_cluster[fI]\n",
    "    neighbour_segments_list = neighbour_segments_frame['XDSegID'].tolist()\n",
    "#     print(neighbour_segments_list)\n",
    "    segment_list = segment_list_per_cluster[fI]\n",
    "#     print(len(segment_list))\n",
    "#     print(len(TR_prediction))\n",
    "#     print( neighbour_segments_frame[neighbour_segments_frame['level']== 1])\n",
    "    actual_affected_segment_count = neighbour_segments_frame[neighbour_segments_frame['level']== 1]['XDSegID'].count()\n",
    "#     print(\"Actual affected segment count for \",fI,\"-th Cluster is: \",actual_affected_segment_count)\n",
    "    if(actual_affected_segment_count == 0):\n",
    "        print(fI,\"th segment has count zero\",actual_affected_segment_count)\n",
    "    predicted_affected_segment_count = 0\n",
    "    for i in range(0,len(TR_prediction)):\n",
    "        if(TR_prediction[i] == 1 ):\n",
    "            if(segment_list[i]  in neighbour_segments_list ):\n",
    "#                 print(neighbour_segments_frame[neighbour_segments_frame['XDSegID']==segment_list[i]]['level'].tolist())\n",
    "                label = neighbour_segments_frame[neighbour_segments_frame['XDSegID']==segment_list[i]]['level'].tolist()[0]\n",
    "#                 print(segment_list[i],':',label)\n",
    "                print(\"segment: \",segment_list[i],\" Trust Score: \",TC[i],' Level: ',label)\n",
    "\n",
    "                if(label == int(1)):\n",
    "                    predicted_affected_segment_count = predicted_affected_segment_count + 1\n",
    "    success_rate = predicted_affected_segment_count/actual_affected_segment_count\n",
    "    if(math.isnan(success_rate) == False):\n",
    "        success_rate_sum = success_rate_sum + success_rate\n",
    "        print(success_rate,predicted_affected_segment_count,actual_affected_segment_count)\n",
    "#     break\n",
    "# print(success_rate_sum)\n",
    "avg_success_rate = success_rate_sum/(len(files_25_ratings))\n",
    "print(avg_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90683cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "18/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check the trust score that has level 0,1,2 with level 3,4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "933272d4630fea264efdf9980c7f4109e56942e385dbe549e42a4761410f6539"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
