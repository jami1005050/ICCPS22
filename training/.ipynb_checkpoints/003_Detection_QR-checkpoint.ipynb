{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decent-cooling",
   "metadata": {},
   "source": [
    "# Fourth Notebook: detection_QR.ipynb\n",
    "* Cross validating on **September** and **October** data\n",
    "* Requires:\n",
    "    * `optimized_safe_margin`\n",
    "    * `optimized_standard_limit`\n",
    "    * `optimized_test_residual`\n",
    "* Generates:\n",
    "    * `optimized_detection_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "communist-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capital-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mature-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "considerable-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime\n",
    "import random\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.dates as md\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from scipy.stats import hmean\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "illegal-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-belgium",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "* Couldn't think of a quick solution to the cluster list since i separated notebooks. just put the length here first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "united-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '06:00'\n",
    "end_time   = '20:55'\n",
    "training_months = (0, 8) # January to August\n",
    "cross_validation_months = (9, 10) # September and October\n",
    "testing_months = (11, 12) # November and December'\n",
    "months = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5,\n",
    "          'june': 6, 'july': 7, 'august': 8, 'september': 9, 'october': 10,\n",
    "          'november': 11, 'december': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nearby-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_version = '0027'\n",
    "cluster_list = [1] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "democratic-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm directories are in place\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../data')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'generated_clusters')):\n",
    "    os.mkdir(os.path.join(data_dir, 'generated_clusters'))\n",
    "cluster_dir = os.path.join(data_dir, 'generated_clusters')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned'))\n",
    "cleaned_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents'))\n",
    "incidents_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT'))\n",
    "incidents_GT_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, f'{clustering_version}_results')):\n",
    "    os.mkdir(os.path.join(data_dir, f'{clustering_version}_results'))\n",
    "results = os.path.join(data_dir, f'{clustering_version}_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-satellite",
   "metadata": {},
   "source": [
    "# Loading cluster list and regenerating filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressing-acquisition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0027_1C_07-09-2021'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_filename = f\"{clustering_version}_{len(cluster_list)}C_{datetime.datetime.now().strftime('%m-%d-%Y')}\"\n",
    "new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opposite-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all clusters\n",
    "\n",
    "fp = os.path.join(cluster_dir, f'{clustering_version}_clusters.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welcome-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1524373007]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join(results, f'used_clusters_list_{new_filename}.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    cluster_list = pickle.load(handle)\n",
    "cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gentle-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fa8de6e4274b50822298281665ebe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimized_detection_report_0027_1C_07-09-2021.pkl\n"
     ]
    }
   ],
   "source": [
    "fp_safe_margin = os.path.join(results, f'optimized_safe_margin_{new_filename}.pkl')\n",
    "with open(fp_safe_margin, 'rb') as handle:\n",
    "    safe_margin = pickle.load(handle)\n",
    "\n",
    "fp_standard_limit = os.path.join(results, f'optimized_standard_limit_{new_filename}.pkl')\n",
    "with open(fp_standard_limit, 'rb') as handle:\n",
    "    standard_limit_5C = pickle.load(handle)\n",
    "standard_limit_5C_Frame = pd.DataFrame(standard_limit_5C)\n",
    "\n",
    "fp_test_res = os.path.join(results, f'optimized_test_residual_{new_filename}.pkl')\n",
    "with open(fp_test_res, 'rb') as handle:\n",
    "    test_residual = pickle.load(handle)\n",
    "\n",
    "info_ratio_incidents = []\n",
    "i = 0\n",
    "test_files = os.listdir(incidents_dir)\n",
    "while i< len(test_files):\n",
    "    fp = os.path.join(incidents_dir, test_files[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        info_ratio_incidents.append( pickle.load(handle))\n",
    "    i+=1\n",
    "combined_ratio_frame_incidents = pd.concat(info_ratio_incidents)\n",
    "\n",
    "testing = combined_ratio_frame_incidents.between_time(start_time, end_time)\n",
    "testing =  testing[(testing.index.month >= months['september']) & (testing.index.month <= months['october']) ]\n",
    "testing_Clist = testing[cluster_list]\n",
    "testing_Clist.columns = cluster_list\n",
    "\n",
    "detection_report = []\n",
    "for column in tqdm(testing_Clist.columns):\n",
    "    grouped = testing_Clist[column].groupby([testing_Clist[column].index.hour,\n",
    "                                             testing_Clist[column].index.minute])\n",
    "\n",
    "    sm_per_C = safe_margin[column] # safe margin list for each cluster\n",
    "    for key in sm_per_C.keys(): # for each safe margin\n",
    "        for key1, group in grouped:\n",
    "            group = group.dropna()\n",
    "\n",
    "            groupDF = pd.DataFrame(group)\n",
    "            groupDF['g_upper'] = groupDF[column] > sm_per_C[key]['upper'][key1]\n",
    "            groupDF['l_lower'] = groupDF[column] < sm_per_C[key]['lower'][key1]\n",
    "            groupDF['or'] = groupDF['g_upper'] | groupDF['l_lower']\n",
    "\n",
    "            groupDF = groupDF[groupDF['or'] == True]\n",
    "            res_SF = test_residual[column][key]\n",
    "            for key2 in res_SF.keys():\n",
    "                std_limit = standard_limit_5C_Frame[(standard_limit_5C_Frame['cluster_id']== column) &\n",
    "                                                    (standard_limit_5C_Frame['ka ppa']== key) &\n",
    "                                                    (standard_limit_5C_Frame['SF']== key2)]\n",
    "                index_ar = std_limit.index\n",
    "                for index, row in groupDF.iterrows():\n",
    "                    temp = None\n",
    "                    if(res_SF[key2][index] >0):\n",
    "                        if(res_SF[key2][index]>std_limit.at[index_ar[0],'tau_max']):\n",
    "                            temp = {'cluster_id':column,'kappa':key,'SF':key2,\n",
    "                                    'time':index,'RUC':res_SF[key2][index],'tau_max':std_limit.at[index_ar[0],'tau_max']}\n",
    "                            detection_report.append(temp)\n",
    "                    else:\n",
    "                        if(res_SF[key2][index]<std_limit.at[index_ar[0],'tau_min']):\n",
    "                            temp = {'cluster_id':column,'kappa':key,'SF':key2,'time':index,\n",
    "                                    'RUC':res_SF[key2][index],'tau_min':std_limit.at[index_ar[0],'tau_min']}\n",
    "                            detection_report.append(temp)\n",
    "\n",
    "detection_report_Frame = pd.DataFrame(detection_report)\n",
    "detection_report_Frame.set_index('time',inplace = True)\n",
    "\n",
    "# Saving and backing up\n",
    "fp = os.path.join(results, f\"optimized_detection_report_{new_filename}.pkl\")\n",
    "detection_report_Frame.to_pickle(fp)\n",
    "print(f\"Saved optimized_detection_report_{new_filename}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-graduation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
