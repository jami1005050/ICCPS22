{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "german-simple",
   "metadata": {},
   "source": [
    "# Second Notebook: standar_limit_QR.ipynb\n",
    "* Calculates $\\tau_{min}$ and $\\tau_{max}$\n",
    "* Uses the new algorithms in the utility.py\n",
    "* Training on **January** to **August** data\n",
    "* Requires:\n",
    "    * `optimized_residual_train`\n",
    "    * `optimized_safe_margin`\n",
    "* Generates:\n",
    "    * `optimized_standard_limit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fourth-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identical-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "plastic-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescription-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime\n",
    "import random\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.dates as md\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from scipy.stats import hmean\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worse-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-jordan",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "* Couldn't think of a quick solution to the cluster list since i separated notebooks. just put the length here first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "turned-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '06:00'\n",
    "end_time   = '20:55'\n",
    "training_months = (0, 8) # January to August\n",
    "cross_validation_months = (9, 10) # September and October\n",
    "testing_months = (11, 12) # November and December'\n",
    "months = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5,\n",
    "          'june': 6, 'july': 7, 'august': 8, 'september': 9, 'october': 10,\n",
    "          'november': 11, 'december': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "superb-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_version = '0027'\n",
    "cluster_list = [1] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "appointed-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm directories are in place\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../data')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'generated_clusters')):\n",
    "    os.mkdir(os.path.join(data_dir, 'generated_clusters'))\n",
    "cluster_dir = os.path.join(data_dir, 'generated_clusters')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned'))\n",
    "cleaned_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents'))\n",
    "incidents_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT'))\n",
    "incidents_GT_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, f'{clustering_version}_results')):\n",
    "    os.mkdir(os.path.join(data_dir, f'{clustering_version}_results'))\n",
    "results = os.path.join(data_dir, f'{clustering_version}_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-contrary",
   "metadata": {},
   "source": [
    "# Loading cluster list and regenerating filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "promotional-cooking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0027_1C_07-09-2021'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_filename = f\"{clustering_version}_{len(cluster_list)}C_{datetime.datetime.now().strftime('%m-%d-%Y')}\"\n",
    "new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recognized-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all clusters\n",
    "\n",
    "fp = os.path.join(cluster_dir, f'{clustering_version}_clusters.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fitting-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1524373007]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join(results, f'used_clusters_list_{new_filename}.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    cluster_list = pickle.load(handle)\n",
    "cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adequate-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_residual = os.path.join(results, f'optimized_residual_train_{new_filename}.pkl')\n",
    "with open(fp_residual, 'rb') as handle:\n",
    "    residual = pickle.load(handle)\n",
    "\n",
    "fp_safe_margin = os.path.join(results, f'optimized_safe_margin_{new_filename}.pkl')\n",
    "with open(fp_safe_margin, 'rb') as handle:\n",
    "    safe_margin = pickle.load(handle)\n",
    "\n",
    "residual_filtered = {}\n",
    "for key in residual.keys():\n",
    "    if(key in cluster_list):\n",
    "        residual_filtered[key] = residual[key]\n",
    "\n",
    "safe_margin_filtered = {}\n",
    "for key in safe_margin.keys():\n",
    "    if(key in cluster_list):\n",
    "        safe_margin_filtered[key] = safe_margin[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "musical-location",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f125f54e2a4e5bb1dd6a3a97b3ffce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimized_standard_limit_0027_1C_07-09-2021.pkl\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(residual_filtered, orient=\"index\").stack().to_frame()\n",
    "df = pd.DataFrame(df[0].values.tolist(), index=df.index)\n",
    "indices = df.index.tolist()\n",
    "sf_keys = df.columns.tolist()\n",
    "\n",
    "standard_limit = []\n",
    "\n",
    "pbar = tqdm(total=(len(indices) * len(sf_keys)))\n",
    "for index in indices:\n",
    "    for sf_key in sf_keys:\n",
    "        _df = pd.DataFrame.from_dict(df.loc[index][sf_key].items())\n",
    "        _df = _df.rename(columns={0:'time', 1: 'nabla'})\n",
    "        _df.set_index('time', inplace=True)\n",
    "        T_max = calculate_tmax(_df['nabla'])\n",
    "        T_min = calculate_tmin(_df['nabla'])\n",
    "        temp = {'cluster_id':index[0],\n",
    "                'ka ppa':index[1],\n",
    "                'SF':sf_key,\n",
    "                'tau_max':T_max, 'tau_min':T_min}\n",
    "        standard_limit.append(temp)\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "# Saving and backing up\n",
    "fp = os.path.join(results, f'optimized_standard_limit_{new_filename}.pkl')\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(standard_limit, handle)\n",
    "    print(f'Saved optimized_standard_limit_{new_filename}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-lloyd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
