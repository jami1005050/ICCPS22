{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunset-membrane",
   "metadata": {},
   "source": [
    "# Sixth Notebook: test_residual_QR.ipynb\n",
    "* Cross validating on **October**, **November**, and **December** data\n",
    "* Requires:\n",
    "    * `optimized_safe_margin`\n",
    "    * `optimized_hyper_mapping`\n",
    "* Generates:\n",
    "    * `optimized_residual`: Not to be confused with `optimized_test_residual` generated in notebook three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addressed-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "signed-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "returning-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime\n",
    "import random\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.dates as md\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from scipy.stats import hmean\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-wealth",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "* Couldn't think of a quick solution to the cluster list since i separated notebooks. just put the length here first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '06:00'\n",
    "end_time   = '20:55'\n",
    "training_months = (0, 8) # January to August\n",
    "cross_validation_months = (9, 10) # September and October\n",
    "testing_months = (11, 12) # November and December'\n",
    "months = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5,\n",
    "          'june': 6, 'july': 7, 'august': 8, 'september': 9, 'october': 10,\n",
    "          'november': 11, 'december': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "logical-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_version = '0027'\n",
    "cluster_list = [1] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "anticipated-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm directories are in place\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../data')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'generated_clusters')):\n",
    "    os.mkdir(os.path.join(data_dir, 'generated_clusters'))\n",
    "cluster_dir = os.path.join(data_dir, 'generated_clusters')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned'))\n",
    "cleaned_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents'))\n",
    "incidents_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT'))\n",
    "incidents_GT_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, f'{clustering_version}_results')):\n",
    "    os.mkdir(os.path.join(data_dir, f'{clustering_version}_results'))\n",
    "results = os.path.join(data_dir, f'{clustering_version}_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-thousand",
   "metadata": {},
   "source": [
    "# Loading cluster list and regenerating filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reflected-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0027_25C_07-14-2021'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_datetime = '07-14-2021'\n",
    "# file_datetime = datetime.datetime.now().strftime('%m-%d-%Y')\n",
    "\n",
    "new_filename = f\"{clustering_version}_{len(cluster_list)}C_{file_datetime}\"\n",
    "new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "extra-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all clusters\n",
    "\n",
    "fp = os.path.join(cluster_dir, f'{clustering_version}_clusters.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coral-arbitration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1524373007,\n",
       " 1524331139,\n",
       " 1524367555,\n",
       " 1524373538,\n",
       " 1524313548,\n",
       " 449629894,\n",
       " 156110240,\n",
       " 1524356290,\n",
       " 1524276985,\n",
       " 449636438,\n",
       " 429350149,\n",
       " 1524355946,\n",
       " 1524343901,\n",
       " 160092856,\n",
       " 441552685,\n",
       " 449614988,\n",
       " 449631121,\n",
       " 1524397645,\n",
       " 1524563195,\n",
       " 1524340452,\n",
       " 449617816,\n",
       " 449614858,\n",
       " 449621051,\n",
       " 449629707,\n",
       " 441420512]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join(results, f'used_clusters_list_{new_filename}.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    cluster_list = pickle.load(handle)\n",
    "cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "outstanding-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_GT = os.listdir(incidents_GT_dir)\n",
    "incident_GT = []\n",
    "i = 0\n",
    "while i< len(files_GT):\n",
    "    fp = os.path.join(incidents_GT_dir, files_GT[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        incident_GT.append( pickle.load(handle))\n",
    "    i+=1\n",
    "incident_GT_Frame = pd.concat(incident_GT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-sydney",
   "metadata": {},
   "source": [
    "# Using the hyper parameters generated through cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "golden-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_safe_margin = os.path.join(results, f'optimized_hyper_mapping_{new_filename}.pkl')\n",
    "with open(fp_safe_margin, 'rb') as handle:\n",
    "    hyper_mapping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "divided-copyright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{156110240: {'kappa': 0.25, 'SF': 3},\n",
       " 160092856: {'kappa': 0.25, 'SF': 3},\n",
       " 429350149: {'kappa': 0.25, 'SF': 3},\n",
       " 441420512: {'kappa': 2.0, 'SF': 9},\n",
       " 441552685: {'kappa': 0.25, 'SF': 7},\n",
       " 449614858: {'kappa': 0.25, 'SF': 5},\n",
       " 449614988: {'kappa': 0.25, 'SF': 5},\n",
       " 449617816: {'kappa': 0.25, 'SF': 7},\n",
       " 449621051: {'kappa': 0.25, 'SF': 3},\n",
       " 449629707: {'kappa': 0.25, 'SF': 3},\n",
       " 449629894: {'kappa': 0.25, 'SF': 9},\n",
       " 449631121: {'kappa': 0.25, 'SF': 5},\n",
       " 449636438: {'kappa': 0.25, 'SF': 9},\n",
       " 1524276985: {'kappa': 0.25, 'SF': 5},\n",
       " 1524313548: {'kappa': 2.0, 'SF': 3},\n",
       " 1524331139: {'kappa': 0.25, 'SF': 3},\n",
       " 1524340452: {'kappa': 0.25, 'SF': 7},\n",
       " 1524343901: {'kappa': 0.25, 'SF': 5},\n",
       " 1524355946: {'kappa': 0.25, 'SF': 3},\n",
       " 1524356290: {'kappa': 0.25, 'SF': 3},\n",
       " 1524367555: {'kappa': 0.25, 'SF': 5},\n",
       " 1524373007: {'kappa': 0.25, 'SF': 5},\n",
       " 1524373538: {'kappa': 0.25, 'SF': 7},\n",
       " 1524397645: {'kappa': 0.25, 'SF': 5},\n",
       " 1524563195: {'kappa': 1.25, 'SF': 5}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-choir",
   "metadata": {},
   "source": [
    "# Manually selecting hyper parameters for checking\n",
    "* Just create a new dictionary of `{cluster_head: {kappa: KAPPA, SF: SF}` for each `cluster_head`\n",
    "* Try to manually limit the `cluster_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bulgarian-timer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{156110240: {'kappa': 0.25, 'SF': 3}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_mapping = {156110240: {'kappa': 0.25, 'SF': 3}}\n",
    "hyper_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-median",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-tonight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "processed-absolute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c857db85ba5e4be18821bed7017ca109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_validated_kappa_SF = hyper_mapping\n",
    "fp_safe_margin = os.path.join(results, f'optimized_safe_margin_{new_filename}.pkl')\n",
    "with open(fp_safe_margin, 'rb') as handle:\n",
    "    safe_margin = pickle.load(handle)\n",
    "\n",
    "test_files = os.listdir(incidents_dir)\n",
    "info_ratio_incidents = []\n",
    "i = 0\n",
    "while i< len(test_files):\n",
    "    fp = os.path.join(incidents_dir, test_files[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        info_ratio_incidents.append( pickle.load(handle))\n",
    "    i+=1\n",
    "combined_ratio_frame_incidents = pd.concat(info_ratio_incidents)\n",
    "\n",
    "combined_ratio_frame_incidents = combined_ratio_frame_incidents.between_time(start_time, end_time)\n",
    "combined_ratio_frame_incidents = combined_ratio_frame_incidents[(combined_ratio_frame_incidents.index.month >= months['october']) \n",
    "                                                              & (combined_ratio_frame_incidents.index.month <= months['december'])]\n",
    "testing = combined_ratio_frame_incidents\n",
    "testing_Clist = testing[list(cross_validated_kappa_SF.keys())]\n",
    "testing_Clist.columns = list(cross_validated_kappa_SF.keys())\n",
    "testing_Clist.columns\n",
    "\n",
    "test_residual = {}\n",
    "for column in tqdm(testing_Clist.columns):\n",
    "    grouped = testing_Clist[column].groupby([testing_Clist[column].index.hour,\n",
    "                                                    testing_Clist[column].index.minute])\n",
    "\n",
    "    sm_per_C = safe_margin[column]\n",
    "    kappa = cross_validated_kappa_SF[column]['kappa']\n",
    "    SF = cross_validated_kappa_SF[column]['SF']\n",
    "    R_per_C = {}\n",
    "    nabla_dict = calculate_nabla(grouped,sm_per_C[kappa])\n",
    "    nabla_frame = pd.DataFrame(list(nabla_dict.items()),columns = ['time','nabla'])\n",
    "    nabla_frame.set_index('time', inplace=True)\n",
    "    _grouped = nabla_frame.groupby(nabla_frame.index.floor('D'))\n",
    "    RUC = {}\n",
    "\n",
    "    RUCsf = {}\n",
    "    for k, group in _grouped:\n",
    "        df = group.rolling(SF, min_periods=SF).sum()\n",
    "        df[0:SF] = group[0:SF]\n",
    "        _RUC = df.to_dict()['nabla']\n",
    "        RUCsf.update(_RUC)\n",
    "\n",
    "    RUC[SF] = RUCsf\n",
    "    R_per_C[kappa] = RUC\n",
    "    test_residual [column] = R_per_C\n",
    "    \n",
    "# Saving and backing up\n",
    "fp = os.path.join(results, f'optimized_residual_Test_QR_{new_filename}_1.pkl')\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(test_residual, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "female-wagon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(test_residual.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-dynamics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
