{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banned-illustration",
   "metadata": {},
   "source": [
    "# First Notebook: training_residual_and_Safe_margin.ipynb\n",
    "* Training on **January** to **August** data\n",
    "* Requires:\n",
    "    * None\n",
    "* Generates:\n",
    "    * `optimized_residual_train`\n",
    "    * `optimized_safe_margin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime\n",
    "import random\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.dates as md\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from scipy.stats import hmean\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acute-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.common_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-netherlands",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "green-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_version = '0027'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "figured-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm directories are in place\n",
    "if not os.path.exists(os.path.join(os.getcwd(), '../data')):\n",
    "    raise OSError(\"Must first download data, see README.md\")\n",
    "data_dir = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, 'generated_clusters')):\n",
    "    os.mkdir(os.path.join(data_dir, 'generated_clusters'))\n",
    "cluster_dir = os.path.join(data_dir, 'generated_clusters')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned'))\n",
    "cleaned_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/cleaned')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents'))\n",
    "incidents_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents')\n",
    "\n",
    "if not os.path.exists(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')):\n",
    "    os.mkdir(os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT'))\n",
    "incidents_GT_dir = os.path.join(cluster_dir, f'{clustering_version}_incident_ratios/incidents_GT')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, f'{clustering_version}_results')):\n",
    "    os.mkdir(os.path.join(data_dir, f'{clustering_version}_results'))\n",
    "results = os.path.join(data_dir, f'{clustering_version}_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "centered-person",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Anomaly_Detection_2021/training/../data/generated_clusters/0027_incident_ratios/cleaned\n",
      "['10_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '09_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '07_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '08_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '02_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '06_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '01_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '11_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '04_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '03_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '12_2019_ratios_0027_gran_5_incidents_cleaned.pkl',\n",
      " '05_2019_ratios_0027_gran_5_incidents_cleaned.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_dir)\n",
    "files = os.listdir(cleaned_dir)\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-thanksgiving",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "* Be sure to run this at the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "supported-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '06:00'\n",
    "end_time   = '20:55'\n",
    "training_months = (0, 8) # January to August\n",
    "cross_validation_months = (9, 10) # September and October\n",
    "testing_months = (11, 12) # November and December'\n",
    "months = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5,\n",
    "          'june': 6, 'july': 7, 'august': 8, 'september': 9, 'october': 10,\n",
    "          'november': 11, 'december': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-bracelet",
   "metadata": {},
   "source": [
    "# Entire Year Data \n",
    "First divide into training and testing to do the rest calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "entitled-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "105108\n"
     ]
    }
   ],
   "source": [
    "info_ratio = []\n",
    "i = 0\n",
    "while i< len(files):\n",
    "    fp = os.path.join(cleaned_dir, files[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        info_ratio.append( pickle.load(handle))\n",
    "    i+=1\n",
    "print(len(info_ratio))\n",
    "combined_ratio_frame = pd.concat(info_ratio)\n",
    "print(len(combined_ratio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "developmental-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43740\n"
     ]
    }
   ],
   "source": [
    "combined_ratio_frame = combined_ratio_frame.between_time(start_time, end_time)\n",
    "combined_ratio_frame =  combined_ratio_frame[(combined_ratio_frame.index.month >= months['january']) & (combined_ratio_frame.index.month <= months['august'])]\n",
    "print(len(combined_ratio_frame))\n",
    "training = combined_ratio_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-italic",
   "metadata": {},
   "source": [
    "# Select Clusters here\n",
    "* Right now it selects the 25 clusters with the most incidents throughout 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "combined-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all clusters\n",
    "\n",
    "fp = os.path.join(cluster_dir, f'{clustering_version}_clusters.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "formal-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_GT = os.listdir(incidents_GT_dir)\n",
    "incident_GT = []\n",
    "i = 0\n",
    "while i< len(files_GT):\n",
    "    fp = os.path.join(incidents_GT_dir, files_GT[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        incident_GT.append( pickle.load(handle))\n",
    "    i+=1\n",
    "incident_GT_Frame = pd.concat(incident_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "scheduled-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the number of clusters\n",
    "NUMBER_OF_CLUSTERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "oriented-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XDSegID</th>\n",
       "      <th>Total_Number_Incidents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1524373007</th>\n",
       "      <td>109521962360</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   XDSegID  Total_Number_Incidents\n",
       "cluster_head                                      \n",
       "1524373007    109521962360                      86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "_df = incident_GT_Frame.groupby('cluster_head').sum()\\\n",
    "                       .sort_values('Total_Number_Incidents', ascending=False).head(NUMBER_OF_CLUSTERS)\n",
    "display(_df.head())\n",
    "cluster_list = _df.index.tolist()\n",
    "print(len(cluster_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-bermuda",
   "metadata": {},
   "source": [
    "# Filename generation\n",
    "> Make sure you run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "limiting-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0027_1C_07-09-2021'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_filename = f\"{clustering_version}_{len(cluster_list)}C_{datetime.datetime.now().strftime('%m-%d-%Y')}\"\n",
    "new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "greatest-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(results, f'used_clusters_list_{new_filename}.pkl')\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(cluster_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "forced-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimized_safe_margin_0027_1C_07-09-2021.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fedc601a354dedba7713fe243f90df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimized_residual_train_0027_1C_07-09-2021.pkl\n"
     ]
    }
   ],
   "source": [
    "info_ratio = []\n",
    "i = 0\n",
    "files = os.listdir(cleaned_dir)\n",
    "while i < len(files):\n",
    "    fp = os.path.join(cleaned_dir, files[i])\n",
    "    with open(fp, 'rb') as handle:\n",
    "        info_ratio.append(pickle.load(handle))\n",
    "    i += 1\n",
    "combined_ratio_frame = pd.concat(info_ratio)\n",
    "\n",
    "combined_ratio_frame = combined_ratio_frame.between_time(start_time, end_time)\n",
    "combined_ratio_frame =  combined_ratio_frame[(combined_ratio_frame.index.month >= months['january']) & (combined_ratio_frame.index.month <= months['august'])]\n",
    "training = combined_ratio_frame\n",
    "\n",
    "training_cluster_list = training[cluster_list]\n",
    "training_cluster_list.columns = cluster_list\n",
    "Q_mean_list = {} # Qmean for each of the cluster \n",
    "for column in training_cluster_list:\n",
    "    Q_mean_list[column] = {}\n",
    "    mad = training_cluster_list[column].mad()\n",
    "    std = training_cluster_list[column].std()\n",
    "    median = training_cluster_list[column].median()\n",
    "    grouped = training_cluster_list[column].groupby([training_cluster_list[column].index.hour,\n",
    "                                                     training_cluster_list[column].index.minute])\n",
    "    Q_mean = {}\n",
    "    for key,group in grouped:\n",
    "        Q_mean[key] = group.mean()\n",
    "    Q_mean_list[column]['Q_mean'] = Q_mean\n",
    "    Q_mean_list[column]['mad'] = mad\n",
    "    Q_mean_list[column]['std'] = std\n",
    "    Q_mean_list[column]['median'] = median\n",
    "\n",
    "# generate safe_margin for all values of kappa\n",
    "kappa_L = [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "safe_margin = {}\n",
    "for key in Q_mean_list.keys():\n",
    "    safe_margin[key] = {}\n",
    "    for k in kappa_L:\n",
    "        safe_margin[key][k] = {'upper':{},'lower':{}}\n",
    "        mad = Q_mean_list[key]['std']\n",
    "\n",
    "        Q_mean = Q_mean_list[key]['Q_mean']\n",
    "        for key1 in Q_mean.keys(): \n",
    "            safe_margin[key][k]['upper'][key1] = Q_mean[key1] + mad * k\n",
    "            safe_margin[key][k]['lower'][key1] = Q_mean[key1] - mad * k\n",
    "\n",
    "fp = os.path.join(results, f'optimized_safe_margin_{new_filename}.pkl')\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(safe_margin, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'Saved optimized_safe_margin_{new_filename}.pkl')\n",
    "    \n",
    "residual = {}\n",
    "\n",
    "for column in tqdm(training_cluster_list.columns):\n",
    "    grouped = training_cluster_list[column].groupby([training_cluster_list[column].index.hour,\n",
    "                                                     training_cluster_list[column].index.minute])\n",
    "    sm_per_C = safe_margin[column]\n",
    "    R_per_C = {}\n",
    "    for key in sm_per_C.keys():\n",
    "        nabla_dict = calculate_nabla(grouped, sm_per_C[key])\n",
    "\n",
    "        nabla_frame = pd.DataFrame(list(nabla_dict.items()),columns = ['time','nabla'])\n",
    "        nabla_frame.set_index('time', inplace=True)\n",
    "        SF_List = [3,5,7,9]\n",
    "        RUC = {}\n",
    "        for sf in SF_List:\n",
    "            RUC[sf] = faster_calculate_residual(nabla_frame,sf)\n",
    "        R_per_C[key] = RUC\n",
    "\n",
    "    residual[column] = R_per_C\n",
    "\n",
    "fp = os.path.join(results, f'optimized_residual_train_{new_filename}.pkl')\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(residual, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'Saved optimized_residual_train_{new_filename}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
